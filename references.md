---
layout: page
title: References 
permalink: /references
---

### Psychological foundation of explanations
1. **Measuring individual differences in implicit cognition: the implicit association test**. *Anthony G. Greenwald, Debbie E. McGhee, Jordan L.K. Schwartz*. Journal of personality and social psychology 1998. [[paper](https://faculty.washington.edu/agg/pdf/Gwald_McGh_Schw_JPSP_1998.OCR.pdf)]
2. **Conversational processes and causal explanation**. *Denis J. Hilton*. Psychological Bulletin 1990. [[paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.391.7282&rep=rep1&type=pdf)] 
3. **Explanation and understanding**. *Frank C. Keil*. Annual Review of Psychology 2006. [[paper](https://cogdevlab.yale.edu/sites/default/files/files/annurev_psych_explan.pdf)]
4. **The structure and function of explanations**. *Tania Lombrozo*. Trends in cognitive sciences 2006. [[paper](http://fitelson.org/few/few_08/lombrozo_reading.pdf)]
5. **A unified approach to interpreting model predictions**. *Scott M. Lundberg, Su-In Lee*. NeurIPS 2017. [[paper](https://papers.nips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html)]
6. **Explanation in human-AI systems: A literature metareview, synopsis of key ideas and publications, and bibliography for explainable AI**. *Shane T. Mueller, Robert R. Hoffman, William Clancey, Abigail Emrey, Gary Klein*. 2019. [[paper](https://arxiv.org/abs/1902.01876)]
7. **Telling more than we can know: verbal reports on mental processes**. *Richard E. Nisbett, Timothy D. Wilson*. Psychological review 1977. [[paper](https://home.csulb.edu/~cwallis/382/readings/482/nisbett%20saying%20more.pdf)]
8. **Experiential Explanation**. *Aronowitz, S., Lombrozo, T.*. Topics in Cognitive Science 2020. [[paper](https://cognition.princeton.edu/publications/experiential-explanation)]
9. **The Explanatory Effect of a Label: Its Influence on a Category Persists Even If We Forget the Label**. *Aslanov, I. A., Sudorgina, Y. V., & Kotov, A. A.*. Frontiers in Psychology 2021 [[paper](https://europepmc.org/article/med/35069325)].
10. **The explanatory effect of a label: Explanations with named categories are more satisfying**. *Giffin, C., Wilkenfeld, D., & Lombrozo, T.*. Cognition 2017. [[paper](https://cognition.princeton.edu/publications/explanatory-effect-label-explanations-named-categories-are-more-satisfying)]
11. **Stability, breadth and guidance**. *Blanchard, T., Vasilyeva, N., & Lombrozo, T.*. Philosophical Studies 2018. [[paper](https://cognition.princeton.edu/publications/stability-breadth-and-guidance)]
12. **Community appeal: Explanation without information**. *Hemmatian, B., & Sloman, S. A.*. Journal of Experimental Psychology: General 2018. [[paper](https://psycnet.apa.org/record/2018-45942-001)]
13. **Folkscience: Coarse interpretations of a complex reality**. *Keil, F. C.*. Trends in cognitive sciences 2003. [[paper](https://cogdevlab.yale.edu/sites/default/files/files/KeilTICS04.pdf)]
14. **How do people know?**. *Kuhn, D.*. Psychological science 2001. [[paper](https://www.tc.columbia.edu/faculty/dk100/faculty-profile/files/Kuhn2001_Howdopeopleknow.pdf)]
15. **Contrastive explanation**. *Lipton, P.*. Royal Institute of Philosophy Supplements 1990. [[paper](https://www.cambridge.org/core/journals/royal-institute-of-philosophy-supplements/article/abs/contrastive-explanation/EB3C55BBB37E6D0B2A88705EBD1F3BA5)]
16. **Explanation and abductive inference.**. *Lombrozo, T.*. Oxford handbook of thinking and reasoning 2012. [[chapter](https://cognition.princeton.edu/sites/default/files/cognition/files/explanation_abductive_inference.pdf)]
17. **Explanatory preferences shape learning and inference**. *Lombrozo, T.*. Trends in Cognitive Sciences 2016. [[paper](https://cognition.princeton.edu/publications/explanatory-preferences-shape-learning-and-inference)]
18. **Mechanistic versus functional understanding.**. *Lombrozo, T., & Wilkenfeld, D.*. Varieties of Understanding: New Perspectives from Philosophy, Psychology, and Theology 2019. [[chapter](https://cognition.princeton.edu/publications/mechanistic-versus-functional-understanding-0)]
19. **The shadows and shallows of explanation**. *Wilson, R. A., & Keil, F.*. Minds and machines 1998. [[paper](https://www.researchgate.net/publication/227151940_The_Shadows_and_Shallows_of_Explanation)]
20. **"Scientific Explanation"**. *Woodward, J. & Ross, L.*. The Stanford Encyclopedia of Philosophy 2021. [[url](https://plato.stanford.edu/archives/sum2021/entries/scientific-explanation/)]

### Explanation methods
1. **Counterfactual visual explanations**. *Yash Goyal, Ziyan Wu, Jan Ernst, Dhruv Batra, Devi Parikh, Stefan Lee*. ICML 2019. [[paper](https://arxiv.org/abs/1904.07451)]
2. **Efficient Data Representation by Selecting Prototypes with Importance Weights**. *Karthik S. Gurumoorthy, Amit Dhurandhar, Guillermo Cecchi, Charu Aggarwal*. ICDM 2019. [[paper](https://arxiv.org/abs/1707.01212)]

### Human subject evaluations
1. **Proxy tasks and subjective measures can be misleading in evaluating explainable ai systems**. *Zana Bu√ßinca, Phoebe Lin, Krzysztof Z Gajos, Elena L. Glassman*. IUI 2020. [[paper](https://arxiv.org/abs/2001.08298)]
2. **Reading tea leaves: How humans interpret topic models**. *Jonathan Chang, Jordan Boyd-Graber, Chong Wang, Sean Gerrish, David M. Blei*. NeurIPS 2009. [[paper](https://papers.nips.cc/paper/2009/hash/f92586a25bb3145facd64ab20fd554ff-Abstract.html)]
3. **Towards a rigorous science of interpretable machine learning**. *Finale Doshi-Velez, Been Kim*. [[paper](https://arxiv.org/abs/1702.08608)]
4. **What can AI do for me? evaluating machine learning interpretations in cooperative play**. *Shi Feng, Jordan Boyd-Graber*. IUI 2019. [[paper](https://arxiv.org/abs/1810.09648)]
5. **Interactive topic modeling**. *Yuening Hu, Jordan Boyd-Graber, Brianna Satinoff*. ACL 2011. [[paper](https://aclanthology.org/P11-1026/)]
6. **On human predictions with explanations and predictions of machine learning models: A case study on deception detection**. *Vivian Lai, Chenhao Tan*. FaCCT 2019. [[paper](https://arxiv.org/abs/1811.07901)]
7. **Questioning the AI: informing design practices for explainable AI user experiences**. *Q Vera Liao, Daniel Gruen, Sarah Miller*. CHI 2020. [[paper](https://arxiv.org/abs/2001.02478)]
8. **Automatic and human evaluation of local topic quality**. *Jeffrey Lund, Piper Armstrong, Wilson Fearn, Stephen Cowley, Courtni Byun, Jordan Boyd-Graber, Kevin Seppi*. ACL 2019. [[paper](https://aclanthology.org/P19-1076/)]

### Evaluation based on human-provided explanations

1. **Evaluating and Characterizing Human Rationales**. *Samuel Carton, Anirudh Rathore, Chenhao Tan*. EMNLP 2020. [[paper](https://arxiv.org/abs/2010.04736)]
2.  **ERASER: A Benchmark to Evaluate Rationalized NLP Models**. *Jay DeYoung, Sarthak Jain, Nazneen Fatema Rajani, Eric Lehman, Caiming Xiong, Richard Socher, Byron C. Wallace*. ACL 2020. [[paper](https://arxiv.org/abs/1911.03429)]
3. **Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences**. *Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, Dan Roth*. NAACL 2018. [[paper](https://aclanthology.org/N18-1023/)]
