---
layout: page
title: References 
permalink: /references
---

### Psychological foundation of explanations
1. **Measuring individual differences in implicit cognition: the implicit association test**. *Anthony G. Greenwald, Debbie E. McGhee, Jordan L.K. Schwartz*. Journal of personality and social psychology 1998. [[paper](https://faculty.washington.edu/agg/pdf/Gwald_McGh_Schw_JPSP_1998.OCR.pdf)]
2. **Conversational processes and causal explanation**. *Denis J. Hilton*. Psychological Bulletin 1990. [[paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.391.7282&rep=rep1&type=pdf)] 
3. **Explanation and understanding**. *Frank C. Keil*. Annual Review of Psychology 2006. [[paper](https://cogdevlab.yale.edu/sites/default/files/files/annurev_psych_explan.pdf)]
4. **The structure and function of explanations**. *Tania Lombrozo*. Trends in cognitive sciences 2006. [[paper](http://fitelson.org/few/few_08/lombrozo_reading.pdf)]
5. **A unified approach to interpreting model predictions**. *Scott M. Lundberg, Su-In Lee*. NeurIPS 2017. [[paper](https://papers.nips.cc/paper/2017/hash/8a20a8621978632d76c43dfd28b67767-Abstract.html)]
6. **Explanation in human-AI systems: A literature metareview, synopsis of key ideas and publications, and bibliography for explainable AI**. *Shane T. Mueller, Robert R. Hoffman, William Clancey, Abigail Emrey, Gary Klein*. 2019. [[paper](https://arxiv.org/abs/1902.01876)]
7. **Telling more than we can know: verbal reports on mental processes**. *Richard E. Nisbett, Timothy D. Wilson*. Psychological review 1977. [[paper](https://home.csulb.edu/~cwallis/382/readings/482/nisbett%20saying%20more.pdf)]
8. **Experiential Explanation**. *Aronowitz, S., Lombrozo, T.*. Topics in Cognitive Science 2020. [[paper](https://cognition.princeton.edu/publications/experiential-explanation)]
9. **The Explanatory Effect of a Label: Its Influence on a Category Persists Even If We Forget the Label**. *Aslanov, I. A., Sudorgina, Y. V., & Kotov, A. A.*. Frontiers in Psychology 2021 [[paper](https://europepmc.org/article/med/35069325)].
10. **The explanatory effect of a label: Explanations with named categories are more satisfying**. *Giffin, C., Wilkenfeld, D., & Lombrozo, T.*. Cognition 2017. [[paper](https://cognition.princeton.edu/publications/explanatory-effect-label-explanations-named-categories-are-more-satisfying)]
11. **Stability, breadth and guidance**. *Blanchard, T., Vasilyeva, N., & Lombrozo, T.*. Philosophical Studies 2018. [[paper](https://cognition.princeton.edu/publications/stability-breadth-and-guidance)]
12. **Community appeal: Explanation without information**. *Hemmatian, B., & Sloman, S. A.*. Journal of Experimental Psychology: General 2018. [[paper](https://psycnet.apa.org/record/2018-45942-001)]
13. **Folkscience: Coarse interpretations of a complex reality**. *Keil, F. C.*. Trends in cognitive sciences 2003. [[paper](https://cogdevlab.yale.edu/sites/default/files/files/KeilTICS04.pdf)]
14. **How do people know?**. *Kuhn, D.*. Psychological science 2001. [[paper](https://www.tc.columbia.edu/faculty/dk100/faculty-profile/files/Kuhn2001_Howdopeopleknow.pdf)]
15. **Contrastive explanation**. *Lipton, P.*. Royal Institute of Philosophy Supplements 1990. [[paper](https://www.cambridge.org/core/journals/royal-institute-of-philosophy-supplements/article/abs/contrastive-explanation/EB3C55BBB37E6D0B2A88705EBD1F3BA5)]
16. **Explanation and abductive inference.**. *Lombrozo, T.*. Oxford handbook of thinking and reasoning 2012. [[chapter](https://cognition.princeton.edu/sites/default/files/cognition/files/explanation_abductive_inference.pdf)]
17. **Explanatory preferences shape learning and inference**. *Lombrozo, T.*. Trends in Cognitive Sciences 2016. [[paper](https://cognition.princeton.edu/publications/explanatory-preferences-shape-learning-and-inference)]
18. **Mechanistic versus functional understanding.**. *Lombrozo, T., & Wilkenfeld, D.*. Varieties of Understanding: New Perspectives from Philosophy, Psychology, and Theology 2019. [[chapter](https://cognition.princeton.edu/publications/mechanistic-versus-functional-understanding-0)]
19. **The shadows and shallows of explanation**. *Wilson, R. A., & Keil, F.*. Minds and machines 1998. [[paper](https://www.researchgate.net/publication/227151940_The_Shadows_and_Shallows_of_Explanation)]
20. **"Scientific Explanation"**. *Woodward, J. & Ross, L.*. The Stanford Encyclopedia of Philosophy 2021. [[url](https://plato.stanford.edu/archives/sum2021/entries/scientific-explanation/)]

### Explanation methods
1. **Counterfactual visual explanations**. *Yash Goyal, Ziyan Wu, Jan Ernst, Dhruv Batra, Devi Parikh, Stefan Lee*. ICML 2019. [[paper](https://arxiv.org/abs/1904.07451)]
2. **Efficient Data Representation by Selecting Prototypes with Importance Weights**. *Karthik S. Gurumoorthy, Amit Dhurandhar, Guillermo Cecchi, Charu Aggarwal*. ICDM 2019. [[paper](https://arxiv.org/abs/1707.01212)]

### Human subject evaluations

- **Towards a rigorous science of interpretable machine learning**. *Doshi-Velez, F., & Kim, B.*. 2017. [[paper](https://arxiv.org/abs/1702.08608)]
- **Proxy tasks and subjective measures can be misleading in evaluating explainable AI systems**. *Bu√ßinca, Z., Lin, P., Gajos, K. Z., & Glassman, E. L.* IUI 2020. [[paper](https://arxiv.org/abs/2001.08298)]
- **Human-Centered Explainable AI (XAI): From Algorithms to User Experiences**. *Liao, Q. V., & Varshney, K. R.*. 2021. [[paper](https://arxiv.org/abs/2110.10790)]
- **Questioning the AI: informing design practices for explainable AI user experiences**. *Liao, Q. V., Gruen, D., & Miller, S.* CHI 2020. [[paper](https://arxiv.org/abs/2001.02478)]
- **Beyond expertise and roles: A framework to characterize the stakeholders of interpretable machine learning and their needs**. *Suresh, H., Gomez, S. R., Nam, K. K., & Satyanarayan, A.*. CHI 2021. [[paper](https://arxiv.org/abs/2101.09824)]
- **On human predictions with explanations and predictions of machine learning models: A case study on deception detection**. *Lai, V., & Tan, C.* FaCCT 2019. [[paper](https://arxiv.org/abs/1811.07901)]
- **Effect of confidence and explanation on accuracy and trust calibration in AI-assisted decision making**. *Zhang, Y., Liao, Q. V., & Bellamy, R. K.*. FaCCT 2020. [[paper](https://arxiv.org/abs/2001.02114)]
- **Are explanations helpful? a comparative study of the effects of explanations in AI-assisted decision-making**. *Wang, X., & Yin, M.*.  IUI 2021. [[paper](https://dl.acm.org/doi/10.1145/3397481.3450650)]
- **Developing and validating trust measures for e-commerce: An integrative typology**. *McKnight, D. H., Choudhury, V., & Kacmar, C.*. Information systems research 2002. [[paper](https://pubsonline.informs.org/doi/10.1287/isre.13.3.334.81)]
- **Explaining decision-making algorithms through UI: Strategies to help non-expert stakeholders**. *Cheng, H. F., Wang, R., Zhang, Z., O'Connell, F., Gray, T., Harper, F. M., & Zhu, H.*. CHI 2019. [[paper](https://www.cs.rochester.edu/u/zzhang95/doc/pub/algorithm_explanation_nonstakeholder.pdf)]
- **Towards a Science of Human-AI Decision Making: A Survey of Empirical Studies**. *Lai, V., Chen, C., Liao, Q. V., Smith-Renner, A., & Tan, C.*. 2021. [[paper](https://arxiv.org/abs/2112.11471)]
- ** Interpreting interpretability: understanding data scientists' use of interpretability tools for machine learning**. *Kaur, H., Nori, H., Jenkins, S., Caruana, R., Wallach, H., & Wortman Vaughan, J.*. CHI 2020. [[paper](http://www-personal.umich.edu/~harmank/Papers/CHI2020_Interpretability.pdf)]
- **Explaining models: an empirical study of how explanations impact fairness judgment**. *Dodge, J., Liao, Q. V., Zhang, Y., Bellamy, R. K., & Dugan, C.*. IUI 2019. [[paper](https://arxiv.org/abs/1901.07694)]


### Evaluation based on human-provided explanations

1. **Evaluating and Characterizing Human Rationales**. *Samuel Carton, Anirudh Rathore, Chenhao Tan*. EMNLP 2020. [[paper](https://arxiv.org/abs/2010.04736)]
2.  **ERASER: A Benchmark to Evaluate Rationalized NLP Models**. *Jay DeYoung, Sarthak Jain, Nazneen Fatema Rajani, Eric Lehman, Caiming Xiong, Richard Socher, Byron C. Wallace*. ACL 2020. [[paper](https://arxiv.org/abs/1911.03429)]
3. **Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences**. *Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, Dan Roth*. NAACL 2018. [[paper](https://aclanthology.org/N18-1023/)]
